{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJxYwKTwkJ2T"
      },
      "source": [
        "# DEFINING THE CORPUS AND IMPORTING THE LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9feUZ4WQQ1d"
      },
      "outputs": [],
      "source": [
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "# Define the corpus\n",
        "corpus = [\n",
        "    \"Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics.\",\n",
        "    \"It is primarily concerned with giving computers the ability to support and manipulate human language.\",\n",
        "    \"It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic machine learning approaches.\",\n",
        "    \"The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them.\",\n",
        "    \"The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\",\n",
        "    \"Machine learning is a field of study in artificial intelligence concerned with the development of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.\",\n",
        "    \"Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.\",\n",
        "    \"Machine learning approaches have been applied to many fields including large language models, computer vision, and speech recognition.\",\n",
        "    \"Machine learning is known in its application across business problems under the name predictive analytics.\",\n",
        "    \"Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3mdoBqWkFCI"
      },
      "source": [
        "# N-gram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jbd1H532hvMj"
      },
      "outputs": [],
      "source": [
        "# Preprocessing the corpus for the N-Gram model\n",
        "\n",
        "def preprocess_corpus(corpus):\n",
        "    return [['<s>'] + sentence.lower().split() + ['</s>'] for sentence in corpus]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60OmZHJmGIxh"
      },
      "outputs": [],
      "source": [
        "# Building the Ngram model\n",
        "def build_n_gram_model(corpus, n=2):\n",
        "    model = defaultdict(Counter)\n",
        "    for sentence in corpus:\n",
        "        for i in range(len(sentence)-n+1):\n",
        "            n_gram_sequence = tuple(sentence[i:i+n-1])\n",
        "            next_word = sentence[i+n-1]\n",
        "            model[n_gram_sequence][next_word] += 1\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a607wL1phypa"
      },
      "outputs": [],
      "source": [
        "# Calculating the N-Gram probabilities\n",
        "\n",
        "def calculate_n_gram_probabilities(model):\n",
        "    probabilities = {}\n",
        "    for n_gram_sequence, words in model.items():\n",
        "        total_count = sum(words.values())\n",
        "        probabilities[n_gram_sequence] = {word: count/total_count for word, count in words.items()}\n",
        "    return probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnd_bekCj5sf"
      },
      "outputs": [],
      "source": [
        "# Calculating the  perplexity for N-Gram model\n",
        "def calculate_perplexity(model, corpus, n=2):\n",
        "    N = sum(len(sentence) for sentence in corpus)\n",
        "    logprob = 0\n",
        "    for sentence in corpus:\n",
        "        for i in range(n-1, len(sentence)):\n",
        "            n_gram_sequence = tuple(sentence[i-n+1:i])\n",
        "            word = sentence[i]\n",
        "            probability = model.get(n_gram_sequence, {}).get(word, 1e-12)  # Smoothing for zero probabilities\n",
        "            logprob += np.log2(probability)\n",
        "    perplexity = 2 ** (-logprob / N)\n",
        "    return perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofOXcCEXGIxi"
      },
      "outputs": [],
      "source": [
        "preprocessed_corpus = preprocess_corpus(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEPlygppGIxi",
        "outputId": "3f569eb4-02fa-4a35-b77d-e616b39cf63f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'processing',\n",
              " '(nlp)',\n",
              " 'is',\n",
              " 'an',\n",
              " 'interdisciplinary',\n",
              " 'subfield',\n",
              " 'of',\n",
              " 'computer',\n",
              " 'science',\n",
              " 'and',\n",
              " 'linguistics.',\n",
              " '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "preprocessed_corpus[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOa4u0YgGIxj",
        "outputId": "5aa332e0-dc21-4de0-c74b-aef11e0b5734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0pFnoCKGIxj",
        "outputId": "d684a6ae-8db5-4e89-eacf-9f82fd9217ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(collections.Counter,\n",
              "            {('<s>',): Counter({'natural': 1,\n",
              "                      'it': 2,\n",
              "                      'the': 2,\n",
              "                      'machine': 3,\n",
              "                      'recently,': 1,\n",
              "                      'although': 1}),\n",
              "             ('natural',): Counter({'language': 2}),\n",
              "             ('language',): Counter({'processing': 1,\n",
              "                      'datasets,': 1,\n",
              "                      'within': 1,\n",
              "                      'models,': 1}),\n",
              "             ('processing',): Counter({'(nlp)': 1, 'natural': 1}),\n",
              "             ('(nlp)',): Counter({'is': 1}),\n",
              "             ('is',): Counter({'an': 2,\n",
              "                      'primarily': 1,\n",
              "                      'a': 2,\n",
              "                      'known': 1,\n",
              "                      'statistically': 1}),\n",
              "             ('an',): Counter({'interdisciplinary': 1, 'important': 1}),\n",
              "             ('interdisciplinary',): Counter({'subfield': 1}),\n",
              "             ('subfield',): Counter({'of': 1}),\n",
              "             ('of',): Counter({'computer': 1,\n",
              "                      'understanding': 1,\n",
              "                      'documents,': 1,\n",
              "                      'the': 2,\n",
              "                      'study': 1,\n",
              "                      'statistical': 1}),\n",
              "             ('computer',): Counter({'science': 1,\n",
              "                      'capable': 1,\n",
              "                      'vision,': 1}),\n",
              "             ('science',): Counter({'and': 1}),\n",
              "             ('and',): Counter({'linguistics.': 1,\n",
              "                      'manipulate': 1,\n",
              "                      'insights': 1,\n",
              "                      'organize': 1,\n",
              "                      'generalize': 1,\n",
              "                      'thus': 1,\n",
              "                      'speech': 1}),\n",
              "             ('linguistics.',): Counter({'</s>': 1}),\n",
              "             ('it',): Counter({'is': 1, 'involves': 1}),\n",
              "             ('primarily',): Counter({'concerned': 1}),\n",
              "             ('concerned',): Counter({'with': 2}),\n",
              "             ('with',): Counter({'giving': 1, 'the': 1}),\n",
              "             ('giving',): Counter({'computers': 1}),\n",
              "             ('computers',): Counter({'the': 1}),\n",
              "             ('the',): Counter({'ability': 1,\n",
              "                      'goal': 1,\n",
              "                      'contents': 1,\n",
              "                      'contextual': 1,\n",
              "                      'language': 1,\n",
              "                      'technology': 1,\n",
              "                      'documents': 2,\n",
              "                      'development': 1,\n",
              "                      'name': 1,\n",
              "                      \"field's\": 1}),\n",
              "             ('ability',): Counter({'to': 1}),\n",
              "             ('to',): Counter({'support': 1,\n",
              "                      'unseen': 1,\n",
              "                      'surpass': 1,\n",
              "                      'many': 1}),\n",
              "             ('support',): Counter({'and': 1}),\n",
              "             ('manipulate',): Counter({'human': 1}),\n",
              "             ('human',): Counter({'language.': 1}),\n",
              "             ('language.',): Counter({'</s>': 1}),\n",
              "             ('involves',): Counter({'processing': 1}),\n",
              "             ('datasets,',): Counter({'such': 1}),\n",
              "             ('such',): Counter({'as': 1}),\n",
              "             ('as',): Counter({'text': 1, 'well': 1, 'categorize': 1}),\n",
              "             ('text',): Counter({'corpora': 1}),\n",
              "             ('corpora',): Counter({'or': 1}),\n",
              "             ('or',): Counter({'speech': 1, 'probabilistic': 1}),\n",
              "             ('speech',): Counter({'corpora,': 1, 'recognition.': 1}),\n",
              "             ('corpora,',): Counter({'using': 1}),\n",
              "             ('using',): Counter({'either': 1}),\n",
              "             ('either',): Counter({'rule-based': 1}),\n",
              "             ('rule-based',): Counter({'or': 1}),\n",
              "             ('probabilistic',): Counter({'machine': 1}),\n",
              "             ('machine',): Counter({'learning': 5}),\n",
              "             ('learning',): Counter({'approaches.': 1,\n",
              "                      'is': 3,\n",
              "                      'approaches': 1}),\n",
              "             ('approaches.',): Counter({'</s>': 1}),\n",
              "             ('goal',): Counter({'is': 1}),\n",
              "             ('a',): Counter({'computer': 1, 'field': 1}),\n",
              "             ('capable',): Counter({'of': 1}),\n",
              "             ('understanding',): Counter({'the': 1}),\n",
              "             ('contents',): Counter({'of': 1}),\n",
              "             ('documents,',): Counter({'including': 1}),\n",
              "             ('including',): Counter({'the': 1, 'large': 1}),\n",
              "             ('contextual',): Counter({'nuances': 1}),\n",
              "             ('nuances',): Counter({'of': 1}),\n",
              "             ('within',): Counter({'them.': 1}),\n",
              "             ('them.',): Counter({'</s>': 1}),\n",
              "             ('technology',): Counter({'can': 1}),\n",
              "             ('can',): Counter({'then': 1, 'learn': 1}),\n",
              "             ('then',): Counter({'accurately': 1}),\n",
              "             ('accurately',): Counter({'extract': 1}),\n",
              "             ('extract',): Counter({'information': 1}),\n",
              "             ('information',): Counter({'and': 1}),\n",
              "             ('insights',): Counter({'contained': 1}),\n",
              "             ('contained',): Counter({'in': 1}),\n",
              "             ('in',): Counter({'the': 1,\n",
              "                      'artificial': 1,\n",
              "                      'performance.': 1,\n",
              "                      'its': 1}),\n",
              "             ('documents',): Counter({'as': 1, 'themselves.': 1}),\n",
              "             ('well',): Counter({'as': 1}),\n",
              "             ('categorize',): Counter({'and': 1}),\n",
              "             ('organize',): Counter({'the': 1}),\n",
              "             ('themselves.',): Counter({'</s>': 1}),\n",
              "             ('field',): Counter({'of': 1}),\n",
              "             ('study',): Counter({'in': 1}),\n",
              "             ('artificial',): Counter({'intelligence': 1, 'neural': 1}),\n",
              "             ('intelligence',): Counter({'concerned': 1}),\n",
              "             ('development',): Counter({'of': 1}),\n",
              "             ('statistical',): Counter({'algorithms': 1}),\n",
              "             ('algorithms',): Counter({'that': 1}),\n",
              "             ('that',): Counter({'can': 1}),\n",
              "             ('learn',): Counter({'from': 1}),\n",
              "             ('from',): Counter({'data': 1}),\n",
              "             ('data',): Counter({'and': 1}),\n",
              "             ('generalize',): Counter({'to': 1}),\n",
              "             ('unseen',): Counter({'data,': 1}),\n",
              "             ('data,',): Counter({'and': 1}),\n",
              "             ('thus',): Counter({'perform': 1}),\n",
              "             ('perform',): Counter({'tasks': 1}),\n",
              "             ('tasks',): Counter({'without': 1}),\n",
              "             ('without',): Counter({'explicit': 1}),\n",
              "             ('explicit',): Counter({'instructions.': 1}),\n",
              "             ('instructions.',): Counter({'</s>': 1}),\n",
              "             ('recently,',): Counter({'generative': 1}),\n",
              "             ('generative',): Counter({'artificial': 1}),\n",
              "             ('neural',): Counter({'networks': 1}),\n",
              "             ('networks',): Counter({'have': 1}),\n",
              "             ('have',): Counter({'been': 2}),\n",
              "             ('been',): Counter({'able': 1, 'applied': 1}),\n",
              "             ('able',): Counter({'to': 1}),\n",
              "             ('surpass',): Counter({'many': 1}),\n",
              "             ('many',): Counter({'previous': 1, 'fields': 1}),\n",
              "             ('previous',): Counter({'approaches': 1}),\n",
              "             ('approaches',): Counter({'in': 1, 'have': 1}),\n",
              "             ('performance.',): Counter({'</s>': 1}),\n",
              "             ('applied',): Counter({'to': 1}),\n",
              "             ('fields',): Counter({'including': 1}),\n",
              "             ('large',): Counter({'language': 1}),\n",
              "             ('models,',): Counter({'computer': 1}),\n",
              "             ('vision,',): Counter({'and': 1}),\n",
              "             ('recognition.',): Counter({'</s>': 1}),\n",
              "             ('known',): Counter({'in': 1}),\n",
              "             ('its',): Counter({'application': 1}),\n",
              "             ('application',): Counter({'across': 1}),\n",
              "             ('across',): Counter({'business': 1}),\n",
              "             ('business',): Counter({'problems': 1}),\n",
              "             ('problems',): Counter({'under': 1}),\n",
              "             ('under',): Counter({'the': 1}),\n",
              "             ('name',): Counter({'predictive': 1}),\n",
              "             ('predictive',): Counter({'analytics.': 1}),\n",
              "             ('analytics.',): Counter({'</s>': 1}),\n",
              "             ('although',): Counter({'not': 1}),\n",
              "             ('not',): Counter({'all': 1}),\n",
              "             ('all',): Counter({'machine': 1}),\n",
              "             ('statistically',): Counter({'based,': 1}),\n",
              "             ('based,',): Counter({'computational': 1}),\n",
              "             ('computational',): Counter({'statistics': 1}),\n",
              "             ('statistics',): Counter({'is': 1}),\n",
              "             ('important',): Counter({'source': 1}),\n",
              "             ('source',): Counter({'of': 1}),\n",
              "             (\"field's\",): Counter({'methods.': 1}),\n",
              "             ('methods.',): Counter({'</s>': 1})})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "n_gram_model = build_n_gram_model(preprocessed_corpus, 2)\n",
        "n_gram_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tv1rQclGIxj"
      },
      "outputs": [],
      "source": [
        "n_gram_probabilities = calculate_n_gram_probabilities(n_gram_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ESxv4pOGIxj",
        "outputId": "411116a7-e75c-4b70-bb33-2122c89db572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example N-Gram probabilities:\n",
            "('<s>',): {'natural': 0.1, 'it': 0.2, 'the': 0.2, 'machine': 0.3, 'recently,': 0.1, 'although': 0.1}\n",
            "('natural',): {'language': 1.0}\n",
            "('language',): {'processing': 0.25, 'datasets,': 0.25, 'within': 0.25, 'models,': 0.25}\n",
            "('processing',): {'(nlp)': 0.5, 'natural': 0.5}\n",
            "('(nlp)',): {'is': 1.0}\n"
          ]
        }
      ],
      "source": [
        "# Print example N-Gram probabilities (for brevity, print probabilities of the first few N-Grams)\n",
        "print(\"Example N-Gram probabilities:\")\n",
        "for n_gram, probabilities in list(n_gram_probabilities.items())[:5]:\n",
        "    print(f\"{n_gram}: {probabilities}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcXfa__dGIxk"
      },
      "outputs": [],
      "source": [
        "n_gram_perplexity = calculate_perplexity(n_gram_probabilities, preprocessed_corpus, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LowBcecj82q",
        "outputId": "e6c4e8ae-49ef-4c18-ab28-bc947949422a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perplexity of the N-Gram model: 1.8121749932026143\n"
          ]
        }
      ],
      "source": [
        "# Print the perplexity of the N-Gram model\n",
        "print(f\"\\nPerplexity of the N-Gram model: {n_gram_perplexity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2kWvdSYGIxk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPHXAWWSGIxk"
      },
      "source": [
        "# N-gram Neural Language Model (e.g., Trigram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Oq07D_BxGIxk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6Pqb-uliGIxk"
      },
      "outputs": [],
      "source": [
        "# Define the corpus\n",
        "corpus = [\n",
        "    \"Natural language processing (NLP) is an interdisciplinary subfield of computer science and linguistics.\",\n",
        "    \"It is primarily concerned with giving computers the ability to support and manipulate human language.\",\n",
        "    \"It involves processing natural language datasets, such as text corpora or speech corpora, using either rule-based or probabilistic machine learning approaches.\",\n",
        "    \"The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them.\",\n",
        "    \"The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.\",\n",
        "    \"Machine learning is a field of study in artificial intelligence concerned with the development of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.\",\n",
        "    \"Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.\",\n",
        "    \"Machine learning approaches have been applied to many fields including large language models, computer vision, and speech recognition.\",\n",
        "    \"Machine learning is known in its application across business problems under the name predictive analytics.\",\n",
        "    \"Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7H1gOXkzGIxk"
      },
      "outputs": [],
      "source": [
        "corpus = '\\n'.join(corpus).split()\n",
        "vocab = set(corpus)\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "idx_to_word = {word_to_idx[word]: word for word in word_to_idx}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1pUc_1pLGIxl"
      },
      "outputs": [],
      "source": [
        "trigram = [((corpus[i], corpus[i + 1]), corpus[i + 2])\n",
        "           for i in range(len(corpus) - 2)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZoFgQ1JYGIxl",
        "outputId": "d92e9a40-3fb2-42db-d485-1aedc8ee1071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('Natural', 'language'), 'processing'),\n",
              " (('language', 'processing'), '(NLP)'),\n",
              " (('processing', '(NLP)'), 'is'),\n",
              " (('(NLP)', 'is'), 'an'),\n",
              " (('is', 'an'), 'interdisciplinary'),\n",
              " (('an', 'interdisciplinary'), 'subfield'),\n",
              " (('interdisciplinary', 'subfield'), 'of'),\n",
              " (('subfield', 'of'), 'computer'),\n",
              " (('of', 'computer'), 'science'),\n",
              " (('computer', 'science'), 'and')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "trigram[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BXkH1WduGIxl"
      },
      "outputs": [],
      "source": [
        "class NgramModel(nn.Module):\n",
        "    def __init__(self, vocb_size, context_size, n_dim):\n",
        "        super(NgramModel, self).__init__()\n",
        "        self.n_word = vocb_size\n",
        "        self.embedding = nn.Embedding(self.n_word, n_dim)\n",
        "        self.linear1 = nn.Linear(context_size * n_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, self.n_word)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        emb = emb.view(1, -1)\n",
        "        out = self.linear1(emb)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        log_prob = F.log_softmax(out)\n",
        "        return log_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i79KaoiBGIxl"
      },
      "outputs": [],
      "source": [
        "# We are buidling a trigram neural langauge model\n",
        "CONTEXT_SIZE = 2\n",
        "ngrammodel = NgramModel(len(word_to_idx), CONTEXT_SIZE, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zPfTqxTGGIxl"
      },
      "outputs": [],
      "source": [
        "# We are optimizing negtive log likelihood loss for this langauge modeling task.\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(ngrammodel.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EtF5JHD8GIxl",
        "outputId": "e9bafb22-670e-4571-d22b-d7491755407d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\n",
            "**********\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-27d4e2c0af34>:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  log_prob = F.log_softmax(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 7.191546\n",
            "epoch: 2\n",
            "**********\n",
            "Loss: 7.107049\n",
            "epoch: 3\n",
            "**********\n",
            "Loss: 7.023870\n",
            "epoch: 4\n",
            "**********\n",
            "Loss: 6.941966\n",
            "epoch: 5\n",
            "**********\n",
            "Loss: 6.860904\n",
            "epoch: 6\n",
            "**********\n",
            "Loss: 6.780304\n",
            "epoch: 7\n",
            "**********\n",
            "Loss: 6.699733\n",
            "epoch: 8\n",
            "**********\n",
            "Loss: 6.619081\n",
            "epoch: 9\n",
            "**********\n",
            "Loss: 6.538334\n",
            "epoch: 10\n",
            "**********\n",
            "Loss: 6.457314\n",
            "epoch: 11\n",
            "**********\n",
            "Loss: 6.375604\n",
            "epoch: 12\n",
            "**********\n",
            "Loss: 6.293319\n",
            "epoch: 13\n",
            "**********\n",
            "Loss: 6.210072\n",
            "epoch: 14\n",
            "**********\n",
            "Loss: 6.126053\n",
            "epoch: 15\n",
            "**********\n",
            "Loss: 6.041139\n",
            "epoch: 16\n",
            "**********\n",
            "Loss: 5.955259\n",
            "epoch: 17\n",
            "**********\n",
            "Loss: 5.868464\n",
            "epoch: 18\n",
            "**********\n",
            "Loss: 5.780504\n",
            "epoch: 19\n",
            "**********\n",
            "Loss: 5.691611\n",
            "epoch: 20\n",
            "**********\n",
            "Loss: 5.602053\n",
            "epoch: 21\n",
            "**********\n",
            "Loss: 5.511841\n",
            "epoch: 22\n",
            "**********\n",
            "Loss: 5.421342\n",
            "epoch: 23\n",
            "**********\n",
            "Loss: 5.330277\n",
            "epoch: 24\n",
            "**********\n",
            "Loss: 5.238912\n",
            "epoch: 25\n",
            "**********\n",
            "Loss: 5.147139\n",
            "epoch: 26\n",
            "**********\n",
            "Loss: 5.054987\n",
            "epoch: 27\n",
            "**********\n",
            "Loss: 4.962533\n",
            "epoch: 28\n",
            "**********\n",
            "Loss: 4.870142\n",
            "epoch: 29\n",
            "**********\n",
            "Loss: 4.777478\n",
            "epoch: 30\n",
            "**********\n",
            "Loss: 4.684692\n",
            "epoch: 31\n",
            "**********\n",
            "Loss: 4.591864\n",
            "epoch: 32\n",
            "**********\n",
            "Loss: 4.498973\n",
            "epoch: 33\n",
            "**********\n",
            "Loss: 4.405986\n",
            "epoch: 34\n",
            "**********\n",
            "Loss: 4.313195\n",
            "epoch: 35\n",
            "**********\n",
            "Loss: 4.220630\n",
            "epoch: 36\n",
            "**********\n",
            "Loss: 4.128196\n",
            "epoch: 37\n",
            "**********\n",
            "Loss: 4.036153\n",
            "epoch: 38\n",
            "**********\n",
            "Loss: 3.944204\n",
            "epoch: 39\n",
            "**********\n",
            "Loss: 3.852524\n",
            "epoch: 40\n",
            "**********\n",
            "Loss: 3.761280\n",
            "epoch: 41\n",
            "**********\n",
            "Loss: 3.670125\n",
            "epoch: 42\n",
            "**********\n",
            "Loss: 3.579341\n",
            "epoch: 43\n",
            "**********\n",
            "Loss: 3.488976\n",
            "epoch: 44\n",
            "**********\n",
            "Loss: 3.399029\n",
            "epoch: 45\n",
            "**********\n",
            "Loss: 3.309570\n",
            "epoch: 46\n",
            "**********\n",
            "Loss: 3.220469\n",
            "epoch: 47\n",
            "**********\n",
            "Loss: 3.131991\n",
            "epoch: 48\n",
            "**********\n",
            "Loss: 3.043965\n",
            "epoch: 49\n",
            "**********\n",
            "Loss: 2.956521\n",
            "epoch: 50\n",
            "**********\n",
            "Loss: 2.869596\n",
            "epoch: 51\n",
            "**********\n",
            "Loss: 2.783470\n",
            "epoch: 52\n",
            "**********\n",
            "Loss: 2.697973\n",
            "epoch: 53\n",
            "**********\n",
            "Loss: 2.613303\n",
            "epoch: 54\n",
            "**********\n",
            "Loss: 2.529476\n",
            "epoch: 55\n",
            "**********\n",
            "Loss: 2.446646\n",
            "epoch: 56\n",
            "**********\n",
            "Loss: 2.364938\n",
            "epoch: 57\n",
            "**********\n",
            "Loss: 2.284382\n",
            "epoch: 58\n",
            "**********\n",
            "Loss: 2.205122\n",
            "epoch: 59\n",
            "**********\n",
            "Loss: 2.127297\n",
            "epoch: 60\n",
            "**********\n",
            "Loss: 2.050979\n",
            "epoch: 61\n",
            "**********\n",
            "Loss: 1.976127\n",
            "epoch: 62\n",
            "**********\n",
            "Loss: 1.902989\n",
            "epoch: 63\n",
            "**********\n",
            "Loss: 1.831600\n",
            "epoch: 64\n",
            "**********\n",
            "Loss: 1.762033\n",
            "epoch: 65\n",
            "**********\n",
            "Loss: 1.694316\n",
            "epoch: 66\n",
            "**********\n",
            "Loss: 1.628612\n",
            "epoch: 67\n",
            "**********\n",
            "Loss: 1.564937\n",
            "epoch: 68\n",
            "**********\n",
            "Loss: 1.503258\n",
            "epoch: 69\n",
            "**********\n",
            "Loss: 1.443700\n",
            "epoch: 70\n",
            "**********\n",
            "Loss: 1.386343\n",
            "epoch: 71\n",
            "**********\n",
            "Loss: 1.331082\n",
            "epoch: 72\n",
            "**********\n",
            "Loss: 1.278047\n",
            "epoch: 73\n",
            "**********\n",
            "Loss: 1.227038\n",
            "epoch: 74\n",
            "**********\n",
            "Loss: 1.178338\n",
            "epoch: 75\n",
            "**********\n",
            "Loss: 1.131738\n",
            "epoch: 76\n",
            "**********\n",
            "Loss: 1.087165\n",
            "epoch: 77\n",
            "**********\n",
            "Loss: 1.044732\n",
            "epoch: 78\n",
            "**********\n",
            "Loss: 1.004349\n",
            "epoch: 79\n",
            "**********\n",
            "Loss: 0.965829\n",
            "epoch: 80\n",
            "**********\n",
            "Loss: 0.929330\n",
            "epoch: 81\n",
            "**********\n",
            "Loss: 0.894592\n",
            "epoch: 82\n",
            "**********\n",
            "Loss: 0.861663\n",
            "epoch: 83\n",
            "**********\n",
            "Loss: 0.830456\n",
            "epoch: 84\n",
            "**********\n",
            "Loss: 0.800844\n",
            "epoch: 85\n",
            "**********\n",
            "Loss: 0.772887\n",
            "epoch: 86\n",
            "**********\n",
            "Loss: 0.746336\n",
            "epoch: 87\n",
            "**********\n",
            "Loss: 0.721313\n",
            "epoch: 88\n",
            "**********\n",
            "Loss: 0.697571\n",
            "epoch: 89\n",
            "**********\n",
            "Loss: 0.675133\n",
            "epoch: 90\n",
            "**********\n",
            "Loss: 0.653950\n",
            "epoch: 91\n",
            "**********\n",
            "Loss: 0.633882\n",
            "epoch: 92\n",
            "**********\n",
            "Loss: 0.614948\n",
            "epoch: 93\n",
            "**********\n",
            "Loss: 0.597029\n",
            "epoch: 94\n",
            "**********\n",
            "Loss: 0.580068\n",
            "epoch: 95\n",
            "**********\n",
            "Loss: 0.564017\n",
            "epoch: 96\n",
            "**********\n",
            "Loss: 0.548860\n",
            "epoch: 97\n",
            "**********\n",
            "Loss: 0.534476\n",
            "epoch: 98\n",
            "**********\n",
            "Loss: 0.520866\n",
            "epoch: 99\n",
            "**********\n",
            "Loss: 0.507953\n",
            "epoch: 100\n",
            "**********\n",
            "Loss: 0.495709\n"
          ]
        }
      ],
      "source": [
        "# We are training by itrating the whole process for 100 times, each time will output the loss value\n",
        "for epoch in range(100):\n",
        "    print('epoch: {}'.format(epoch + 1))\n",
        "    print('*' * 10)\n",
        "    running_loss = 0\n",
        "    for data in trigram:\n",
        "        word, label = data     #E.g., word = ('Natural', 'language'); label = 'processing'\n",
        "        word = Variable(torch.LongTensor([word_to_idx[i] for i in word]))\n",
        "        label = Variable(torch.LongTensor([word_to_idx[label]]))\n",
        "\n",
        "        # forward -- for prediction and calculating the loss for each instance\n",
        "        out = ngrammodel(word)\n",
        "        loss = criterion(out, label)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # backward -- for gradiate update\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # print the average loss\n",
        "    print('Loss: {:.6f}'.format(running_loss / len(word_to_idx)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSfPv_6zGIxm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZUC09bKFGIxm",
        "outputId": "1d31096c-0fa9-4532-cf6a-f28eeca9c9c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('(NLP)', 'is') \t an\n"
          ]
        }
      ],
      "source": [
        "# Now let's testing\n",
        "# Suppose our testing case is: given '(NLP) is', output 'an'\n",
        "\n",
        "word, label = trigram[3]\n",
        "print(word, '\\t', label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fRrbkC8CGIxm",
        "outputId": "2d9a6d3f-5ee0-4d88-c58c-196f3488aff6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61 \t 89\n"
          ]
        }
      ],
      "source": [
        "print(word_to_idx['(NLP)'], '\\t', word_to_idx['is'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZsbQbnpmGIxm",
        "outputId": "653156f3-a1a2-4362-f362-b33fe76907e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-27d4e2c0af34>:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  log_prob = F.log_softmax(out)\n"
          ]
        }
      ],
      "source": [
        "word = Variable(torch.LongTensor([word_to_idx[i] for i in word]))\n",
        "out = ngrammodel(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Rx09Gl6lGIxm",
        "outputId": "d16785d8-7339-4745-de24-8d4629d159f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-10.4696,  -8.1890,  -7.1613, -10.2673,  -7.7854,  -6.8352,  -7.6468,\n",
              "          -9.4642,  -6.9517,  -9.3639,  -8.8288,  -6.1360,  -8.2456,  -5.1004,\n",
              "          -7.8550,  -7.8797,  -7.1737,  -8.9314,  -7.5029,  -8.1449,  -0.1588,\n",
              "          -8.4978,  -8.8739,  -8.4508,  -7.6528,  -8.1161,  -9.7926,  -3.0777,\n",
              "          -6.8153,  -7.6515,  -8.5922,  -8.4576,  -8.1637,  -4.1588,  -7.8781,\n",
              "          -8.9163,  -8.5277,  -8.1280,  -4.9791,  -8.1334,  -8.4802,  -7.2859,\n",
              "          -7.6268,  -8.2424,  -7.8836,  -6.8924,  -8.0658,  -8.6845,  -4.8076,\n",
              "          -7.6160,  -8.7249,  -6.7079,  -9.2927,  -9.9076,  -8.2134,  -8.7413,\n",
              "          -8.5173,  -8.1099,  -8.7992,  -6.6223,  -7.7032,  -9.2457,  -8.1872,\n",
              "          -8.6842,  -8.4832,  -7.3168,  -8.5292,  -8.2972,  -8.6396,  -9.3382,\n",
              "          -8.0006,  -6.9437,  -8.7278,  -8.5051,  -7.1226,  -7.4214,  -7.7384,\n",
              "          -6.3909,  -7.4097,  -7.6035,  -7.4354,  -8.1616,  -5.6515,  -7.9523,\n",
              "          -8.3122,  -7.7721,  -8.4252,  -7.3988,  -6.9376,  -8.4044,  -7.7773,\n",
              "          -7.5959,  -7.5982,  -7.7432,  -7.9889,  -9.0456,  -7.2932,  -8.7351,\n",
              "          -4.6315,  -8.7330,  -7.1403,  -8.7941,  -7.8904,  -8.9336,  -9.2269,\n",
              "          -9.4573,  -8.0260,  -7.2584,  -7.5990,  -8.7434,  -7.7769,  -8.1072,\n",
              "          -7.5128,  -7.1629,  -8.3838,  -6.7014,  -8.5913,  -8.2320,  -7.9105,\n",
              "          -7.5516,  -9.4400,  -8.4802,  -7.1854,  -7.6715,  -7.8501,  -7.8749,\n",
              "          -8.2517,  -7.7061,  -6.6248]], grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# the intermediate representation of the predicted word\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MVuqyw64GIxn"
      },
      "outputs": [],
      "source": [
        "_, predict_label = torch.max(out, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A0u58knPGIxn",
        "outputId": "35f28347-9dc5-4d21-fdfc-854274c5679b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([20])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "predict_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "E19oqwcCGIxn",
        "outputId": "60ec49b2-6ad2-491e-f766-da62af49bb52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real word is: an,\n",
            "predict word is: an\n"
          ]
        }
      ],
      "source": [
        "predict_word = idx_to_word[predict_label.item()]\n",
        "print('real word is: {},\\npredict word is: {}'.format(label, predict_word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF9_upCLGIxo"
      },
      "source": [
        "Validation set can avoid overfitting\n",
        "N-gram overlapping"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}